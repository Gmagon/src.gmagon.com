---
title: Facebook’s human-like AI learns human reactions
---

![](https://d1o50x50snmhul.cloudfront.net/wp-content/uploads/2017/09/04173946/gettyimages-631314162-800x533.jpg)Naturalistic reactions are the way to evade the uncanny valley
Johannes Eisele/AFP/Getty Images
ByMatt Reynolds

There’s something not quite right about humanoid robots. They are cute up to a point, but once they become a bit too realistic, they often[start to creep us out](https://www.newscientist.com/article/mg23230970-500-exploring-the-uncanny-valley-why-almosthuman-is-creepy/)– a foible called the uncanny valley. Now Facebook wants robots to climb their way out of it.

Researchers at[Facebook’s AI lab](https://research.fb.com/category/facebook-ai-research-fair/)have developed an expressive bot, an animation controlled by an artificially intelligent algorithm. The algorithm was trained on hundreds of[videos of Skype conversations](https://www.newscientist.com/article/mg23231040-300-dont-believe-the-skype-we-never-wanted-to-video-call-people/), so that it could learn and then mimic how humans adjust their expressions in response to each other. In tests, it successfully passed as human-like.

#### What will happen when computers get access to your emotions?[Find out in our expert talk at New Scientist Live](https://live.newscientist.com/talks/when-computers-get-access-to-your-emotions/?cmpid=ILC|NSNSL|2017-UK-nslive17|editoriallink&utm_medium=ILC&utm_source=NSNSL&utm_campaign=nslive17&utm_content=editoriallink)

To optimise its learning, the algorithm divided the human face into 68 key points that it monitored throughout each Skype conversation. People naturally produce nods, blinks and various mouth movements to show they are engaged with the person they are talking to, and eventually the system learned to do this too.

The bot was then able to look at a video of a human speaking, and choose in real time what the most appropriate facial response would be. If the person was laughing, for example, the bot might choose to open its mouth too, or tilt its head.

The Facebook team then tested the system with panels of people who watched animations that included both the bot reacting to a human, and a human reacting to a human. The volunteers judged the bot and the human to be equally natural and realistic.

However, as the animations were quite basic, it’s not clear whether a humanoid robot powered by this algorithm would have natural-seeming reactions.

Additionally, learning the basic rules of facial communication might not be enough to create truly realistic conversation partners, says[Goren Gordon](https://english.tau.ac.il/profile/gorengor)at Tel Aviv University in Israel. “Actual facial expressions are based on what you are thinking and feeling.”

In this case, the Facebook system ends up creating a kind of “average personality”, says[Louis-Philippe Morency](https://www.cs.cmu.edu/~morency/)at Carnegie Mellon University in Pittsburgh. In future, more sophisticated bots might be able to pick from a range of personalities or adapt their own to match the person they are talking to.

Robots aren’t so good at mastering these subtle elements of human interaction, says Gordon. We already know that humans prefer speaking with robots that[mimic their own facial expression](https://www.newscientist.com/article/dn15055-mummy-that-robot-is-making-faces-at-me/), he says, but now Facebook is trying to take robot conversations to the next level. “At some point we’ll get out of the uncanny valley and come out at the other side.”

Facebook will[present the work](https://www.dropbox.com/s/ljfnv3i1jw0uzbh/learn2smile-learning-verbal.pdf?dl=0)at the[International Conference on Intelligent Robots and Systems](https://www.iros2017.org/)in Vancouver, Canada, later this month.

Source: https://www.newscientist.com/article/2146294-facebook-ai-learns-human-reactions-after-watching-hours-of-skype/

